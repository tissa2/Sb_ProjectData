{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>accumulate</th>\n",
       "      <th>accumulation</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>acwi</th>\n",
       "      <th>add</th>\n",
       "      <th>address</th>\n",
       "      <th>adjust</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "      <th>zealand</th>\n",
       "      <th>Price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_month_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>184</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,783.30</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,776.80</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,771.60</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,763.60</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 629 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date  accumulate  accumulation  act  action  acwi  add  \\\n",
       "0           0  2021-07-03         0.0           0.0  0.0     0.0   0.0  0.0   \n",
       "1           1  2021-07-02         0.0           0.0  0.0     0.0   0.0  0.0   \n",
       "2           2  2021-07-01         0.0           0.0  0.0     0.0   0.0  0.0   \n",
       "3           3  2021-06-30         0.0           0.0  0.0     0.0   0.0  0.0   \n",
       "4           4  2021-06-29         0.0           0.0  0.0     0.0   0.0  0.0   \n",
       "\n",
       "   address  adjust  ...  yesterday     young  zealand     Price  year  month  \\\n",
       "0      0.0     0.0  ...        0.0  0.316228      0.0       NaN  2021      7   \n",
       "1      0.0     0.0  ...        0.0  0.000000      0.0  1,783.30  2021      7   \n",
       "2      0.0     0.0  ...        0.0  0.000000      0.0  1,776.80  2021      7   \n",
       "3      0.0     0.0  ...        0.0  0.000000      0.0  1,771.60  2021      6   \n",
       "4      0.0     0.0  ...        0.0  0.000000      0.0  1,763.60  2021      6   \n",
       "\n",
       "   day  dayofyear  is_month_end  is_month_start  \n",
       "0    3        184         False           False  \n",
       "1    2        183         False           False  \n",
       "2    1        182         False            True  \n",
       "3   30        181          True           False  \n",
       "4   29        180         False           False  \n",
       "\n",
       "[5 rows x 629 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_process-merge-data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>accumulate</th>\n",
       "      <th>accumulation</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>acwi</th>\n",
       "      <th>add</th>\n",
       "      <th>address</th>\n",
       "      <th>adjust</th>\n",
       "      <th>admit</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "      <th>zealand</th>\n",
       "      <th>Price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_month_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>184</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,783.30</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,776.80</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,771.60</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,763.60</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 628 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  accumulate  accumulation  act  action  acwi  add  address  \\\n",
       "0  2021-07-03         0.0           0.0  0.0     0.0   0.0  0.0      0.0   \n",
       "1  2021-07-02         0.0           0.0  0.0     0.0   0.0  0.0      0.0   \n",
       "2  2021-07-01         0.0           0.0  0.0     0.0   0.0  0.0      0.0   \n",
       "3  2021-06-30         0.0           0.0  0.0     0.0   0.0  0.0      0.0   \n",
       "4  2021-06-29         0.0           0.0  0.0     0.0   0.0  0.0      0.0   \n",
       "\n",
       "   adjust  admit  ...  yesterday     young  zealand     Price  year  month  \\\n",
       "0     0.0    0.0  ...        0.0  0.316228      0.0       NaN  2021      7   \n",
       "1     0.0    0.0  ...        0.0  0.000000      0.0  1,783.30  2021      7   \n",
       "2     0.0    0.0  ...        0.0  0.000000      0.0  1,776.80  2021      7   \n",
       "3     0.0    0.0  ...        0.0  0.000000      0.0  1,771.60  2021      6   \n",
       "4     0.0    0.0  ...        0.0  0.000000      0.0  1,763.60  2021      6   \n",
       "\n",
       "   day  dayofyear  is_month_end  is_month_start  \n",
       "0    3        184         False           False  \n",
       "1    2        183         False           False  \n",
       "2    1        182         False            True  \n",
       "3   30        181          True           False  \n",
       "4   29        180         False           False  \n",
       "\n",
       "[5 rows x 628 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>accumulate</th>\n",
       "      <th>accumulation</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>acwi</th>\n",
       "      <th>add</th>\n",
       "      <th>address</th>\n",
       "      <th>adjust</th>\n",
       "      <th>admit</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "      <th>zealand</th>\n",
       "      <th>Price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_month_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,783.30</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,776.80</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,771.60</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,763.60</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,780.70</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>179</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 628 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  accumulate  accumulation  act  action  acwi  add   address  \\\n",
       "1  2021-07-02         0.0      0.000000  0.0     0.0   0.0  0.0  0.000000   \n",
       "2  2021-07-01         0.0      0.000000  0.0     0.0   0.0  0.0  0.000000   \n",
       "3  2021-06-30         0.0      0.000000  0.0     0.0   0.0  0.0  0.000000   \n",
       "4  2021-06-29         0.0      0.000000  0.0     0.0   0.0  0.0  0.000000   \n",
       "5  2021-06-28         0.0      0.408248  0.0     0.0   0.0  0.0  0.408248   \n",
       "\n",
       "   adjust  admit  ...  yesterday  young  zealand     Price  year  month  day  \\\n",
       "1     0.0    0.0  ...        0.0    0.0      0.0  1,783.30  2021      7    2   \n",
       "2     0.0    0.0  ...        0.0    0.0      0.0  1,776.80  2021      7    1   \n",
       "3     0.0    0.0  ...        0.0    0.0      0.0  1,771.60  2021      6   30   \n",
       "4     0.0    0.0  ...        0.0    0.0      0.0  1,763.60  2021      6   29   \n",
       "5     0.0    0.0  ...        0.0    0.0      0.0  1,780.70  2021      6   28   \n",
       "\n",
       "   dayofyear  is_month_end  is_month_start  \n",
       "1        183         False           False  \n",
       "2        182         False            True  \n",
       "3        181          True           False  \n",
       "4        180         False           False  \n",
       "5        179         False           False  \n",
       "\n",
       "[5 rows x 628 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price'] = df['Price'].str.replace(',', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 133 entries, 1 to 183\n",
      "Columns: 628 entries, Date to is_month_start\n",
      "dtypes: bool(2), float64(620), int64(5), object(1)\n",
      "memory usage: 651.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Year Column since it is fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('year',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>accumulate</th>\n",
       "      <th>accumulation</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>acwi</th>\n",
       "      <th>add</th>\n",
       "      <th>address</th>\n",
       "      <th>adjust</th>\n",
       "      <th>admit</th>\n",
       "      <th>...</th>\n",
       "      <th>xbox</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "      <th>zealand</th>\n",
       "      <th>Price</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_month_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1783.3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1776.8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1771.6</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1763.6</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1780.7</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>179</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 627 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  accumulate  accumulation  act  action  acwi  add   address  \\\n",
       "1  2021-07-02         0.0      0.000000  0.0     0.0   0.0  0.0  0.000000   \n",
       "2  2021-07-01         0.0      0.000000  0.0     0.0   0.0  0.0  0.000000   \n",
       "3  2021-06-30         0.0      0.000000  0.0     0.0   0.0  0.0  0.000000   \n",
       "4  2021-06-29         0.0      0.000000  0.0     0.0   0.0  0.0  0.000000   \n",
       "5  2021-06-28         0.0      0.408248  0.0     0.0   0.0  0.0  0.408248   \n",
       "\n",
       "   adjust  admit  ...  xbox  yesterday  young  zealand   Price  month  day  \\\n",
       "1     0.0    0.0  ...   0.0        0.0    0.0      0.0  1783.3      7    2   \n",
       "2     0.0    0.0  ...   0.0        0.0    0.0      0.0  1776.8      7    1   \n",
       "3     0.0    0.0  ...   0.0        0.0    0.0      0.0  1771.6      6   30   \n",
       "4     0.0    0.0  ...   0.0        0.0    0.0      0.0  1763.6      6   29   \n",
       "5     0.0    0.0  ...   0.0        0.0    0.0      0.0  1780.7      6   28   \n",
       "\n",
       "   dayofyear  is_month_end  is_month_start  \n",
       "1        183         False           False  \n",
       "2        182         False            True  \n",
       "3        181          True           False  \n",
       "4        180         False           False  \n",
       "5        179         False           False  \n",
       "\n",
       "[5 rows x 627 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate categorical from continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'accumulate', 'accumulation', 'act', 'action', 'acwi', 'add',\n",
       "       'address', 'adjust', 'admit',\n",
       "       ...\n",
       "       'xbox', 'yesterday', 'young', 'zealand', 'Price', 'month', 'day',\n",
       "       'dayofyear', 'is_month_end', 'is_month_start'],\n",
       "      dtype='object', length=627)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['day','month', 'is_month_start', 'is_month_end']\n",
    "y_col = ['Price']  # this column contains the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = [col for col in df.columns if col not in cat_cols + y_col+['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cont_cols "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our four categorical columns to category dtypes.\n",
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                object\n",
       "accumulate         float64\n",
       "accumulation       float64\n",
       "act                float64\n",
       "action             float64\n",
       "                    ...   \n",
       "month             category\n",
       "day               category\n",
       "dayofyear            int64\n",
       "is_month_end      category\n",
       "is_month_start    category\n",
       "Length: 627, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7\n",
       "2    7\n",
       "3    6\n",
       "4    6\n",
       "5    6\n",
       "Name: month, dtype: category\n",
       "Categories (7, int64): [1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     2\n",
       "2     1\n",
       "3    30\n",
       "4    29\n",
       "5    28\n",
       "Name: day, dtype: category\n",
       "Categories (31, int64): [1, 2, 3, 4, ..., 28, 29, 30, 31]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['day'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    False\n",
       "2    False\n",
       "3     True\n",
       "4    False\n",
       "5    False\n",
       "Name: is_month_end, dtype: category\n",
       "Categories (2, object): [False, True]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_month_end'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "Name: is_month_start, dtype: category\n",
       "Categories (2, object): [False, True]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_month_start'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "            18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['day'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  0, 29, 28, 27, 24, 23, 22, 21, 20, 17, 16, 15, 14, 13, 10,  9,\n",
       "        8,  7,  6,  3,  2,  1,  0, 30, 29, 27, 26, 25, 24, 23, 20, 19, 18,\n",
       "       17, 16, 13, 12, 11, 10,  9,  6,  5,  4,  3,  2, 29, 28, 27, 26, 25,\n",
       "       22, 21, 20, 19, 18, 15, 14, 13, 12, 11,  8,  7,  6,  5,  4,  0, 30,\n",
       "       29, 28, 25, 24, 23, 22, 21, 18, 17, 16, 15, 14, 11, 10,  9,  8,  7,\n",
       "        4,  3,  2,  1,  0, 25, 24, 23, 22, 21, 18, 17, 16, 15, 14, 13, 11,\n",
       "       10,  9,  8,  7,  4,  3,  2,  1,  0, 28, 27, 26, 25, 24, 21, 20, 19,\n",
       "       18, 17, 16, 14, 13, 12, 11, 10,  7,  6,  5,  4,  3,  0], dtype=int8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['day'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  6,  0,  0],\n",
       "       [ 0,  6,  1,  0],\n",
       "       [29,  5,  0,  1],\n",
       "       [28,  5,  0,  0],\n",
       "       [27,  5,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day = df['day'].cat.codes.values\n",
    "month = df['month'].cat.codes.values\n",
    "m_end = df['is_month_end'].cat.codes.values\n",
    "m_start = df['is_month_start'].cat.codes.values\n",
    "\n",
    "cats = np.stack([day, month, m_start,m_end], 1)\n",
    "\n",
    "cats[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  6,  0,  0],\n",
       "       [ 0,  6,  1,  0],\n",
       "       [29,  5,  0,  1],\n",
       "       [28,  5,  0,  0],\n",
       "       [27,  5,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or in one line of code\n",
    "cats = np.stack([df[col].cat.codes.values for col in cat_cols], 1)\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  6,  0,  0],\n",
       "       [ 0,  6,  1,  0],\n",
       "       [29,  5,  0,  1],\n",
       "       [28,  5,  0,  0],\n",
       "       [27,  5,  0,  0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = cats.astype('int32')\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert numpy arrays to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  6,  0,  0],\n",
       "        [ 0,  6,  1,  0],\n",
       "        [29,  5,  0,  1],\n",
       "        [28,  5,  0,  0],\n",
       "        [27,  5,  0,  0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical variables to a tensor\n",
    "cats = torch.tensor(cats, dtype=torch.int64) \n",
    "\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000, 183.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000, 182.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000, 181.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000, 180.0000],\n",
       "        [  0.0000,   0.4082,   0.0000,  ...,   0.0000,   0.0000, 179.0000]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert continuous variables to a tensor\n",
    "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1783.3000],\n",
       "        [1776.8000],\n",
       "        [1771.6000],\n",
       "        [1763.6000],\n",
       "        [1780.7000]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert labels to a tensor\n",
    "y = torch.tensor(df[y_col].values, dtype=torch.float).reshape(-1,1)\n",
    "\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([133, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([133, 621])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([133, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set an embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(31, 16), (7, 4), (2, 1), (2, 1)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will set embedding sizes for categorical variables\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a TabularModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  6,  0,  0],\n",
       "        [ 0,  6,  1,  0],\n",
       "        [29,  5,  0,  1],\n",
       "        [28,  5,  0,  0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our source data\n",
    "catz = cats[:4]\n",
    "catz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(31, 16), (7, 4), (2, 1), (2, 1)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is passed in when the model is instantiated\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(31, 16)\n",
       "  (1): Embedding(7, 4)\n",
       "  (2): Embedding(2, 1)\n",
       "  (3): Embedding(2, 1)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is assigned inside the __init__() method\n",
    "selfembeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "selfembeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, Embedding(31, 16)),\n",
       " (1, Embedding(7, 4)),\n",
       " (2, Embedding(2, 1)),\n",
       " (3, Embedding(2, 1))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(selfembeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.4130, -0.9648, -1.5140, -0.7966, -1.3037, -0.5035, -0.3979,  0.4411,\n",
       "           0.6476, -0.3957, -0.1532,  0.6746, -1.9132, -1.5161, -1.0182, -0.2471],\n",
       "         [-2.0103,  1.5139, -0.9502,  1.1905,  2.3837, -0.6534,  1.8693, -0.6700,\n",
       "          -0.7442, -1.6495, -2.4100, -0.3593,  0.3400, -0.5272,  1.5866,  0.5682],\n",
       "         [-0.5158,  0.3274,  0.1366,  1.4445, -0.4759,  2.0416, -1.7239, -0.1337,\n",
       "           0.6362, -0.4606,  1.2907, -0.6875,  0.2110,  0.0522,  0.0099,  0.5343],\n",
       "         [-1.2217, -0.3834, -0.6039, -0.5562,  0.4417,  1.1865,  0.8354,  0.4736,\n",
       "          -0.2570, -0.9893,  2.3451, -0.8578,  0.8087, -0.6549,  1.1674,  0.4675]],\n",
       "        grad_fn=<EmbeddingBackward>),\n",
       " tensor([[ 0.2093, -0.6206, -0.5751,  0.5055],\n",
       "         [ 0.2093, -0.6206, -0.5751,  0.5055],\n",
       "         [ 0.7779,  0.2944,  1.1667, -0.4073],\n",
       "         [ 0.7779,  0.2944,  1.1667, -0.4073]], grad_fn=<EmbeddingBackward>),\n",
       " tensor([[ 1.2057],\n",
       "         [-0.2060],\n",
       "         [ 1.2057],\n",
       "         [ 1.2057]], grad_fn=<EmbeddingBackward>),\n",
       " tensor([[0.2251],\n",
       "         [0.2251],\n",
       "         [0.5543],\n",
       "         [0.2251]], grad_fn=<EmbeddingBackward>)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This happens inside the forward() method\n",
    "embeddingz = []\n",
    "for i,e in enumerate(selfembeds):\n",
    "    embeddingz.append(e(catz[:,i]))\n",
    "embeddingz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4130, -0.9648, -1.5140, -0.7966, -1.3037, -0.5035, -0.3979,  0.4411,\n",
       "          0.6476, -0.3957, -0.1532,  0.6746, -1.9132, -1.5161, -1.0182, -0.2471,\n",
       "          0.2093, -0.6206, -0.5751,  0.5055,  1.2057,  0.2251],\n",
       "        [-2.0103,  1.5139, -0.9502,  1.1905,  2.3837, -0.6534,  1.8693, -0.6700,\n",
       "         -0.7442, -1.6495, -2.4100, -0.3593,  0.3400, -0.5272,  1.5866,  0.5682,\n",
       "          0.2093, -0.6206, -0.5751,  0.5055, -0.2060,  0.2251],\n",
       "        [-0.5158,  0.3274,  0.1366,  1.4445, -0.4759,  2.0416, -1.7239, -0.1337,\n",
       "          0.6362, -0.4606,  1.2907, -0.6875,  0.2110,  0.0522,  0.0099,  0.5343,\n",
       "          0.7779,  0.2944,  1.1667, -0.4073,  1.2057,  0.5543],\n",
       "        [-1.2217, -0.3834, -0.6039, -0.5562,  0.4417,  1.1865,  0.8354,  0.4736,\n",
       "         -0.2570, -0.9893,  2.3451, -0.8578,  0.8087, -0.6549,  1.1674,  0.4675,\n",
       "          0.7779,  0.2944,  1.1667, -0.4073,  1.2057,  0.2251]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We concatenate the embedding sections (16,4,1,1) into one (22)\n",
    "z = torch.cat(embeddingz, 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was assigned under the __init__() method\n",
    "selfembdrop = nn.Dropout(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.0000, -2.5233, -1.3276, -2.1728, -0.8392, -0.6632,  0.7352,\n",
       "          1.0793, -0.0000, -0.2553,  1.1244, -3.1886, -2.5269, -1.6971, -0.0000,\n",
       "          0.0000, -0.0000, -0.9585,  0.8426,  0.0000,  0.3751],\n",
       "        [-3.3505,  2.5231, -0.0000,  1.9841,  0.0000, -1.0891,  3.1155, -1.1167,\n",
       "         -1.2404, -2.7492, -0.0000, -0.5989,  0.0000, -0.8787,  0.0000,  0.0000,\n",
       "          0.3489, -1.0344, -0.9585,  0.8426, -0.0000,  0.3751],\n",
       "        [-0.8597,  0.0000,  0.2277,  2.4074, -0.0000,  3.4026, -0.0000, -0.2229,\n",
       "          0.0000, -0.7676,  2.1512, -1.1459,  0.3516,  0.0871,  0.0165,  0.0000,\n",
       "          1.2965,  0.4906,  1.9445, -0.6788,  2.0095,  0.9238],\n",
       "        [-2.0362, -0.0000, -1.0065, -0.9269,  0.7362,  0.0000,  1.3923,  0.0000,\n",
       "         -0.4283, -0.0000,  3.9085, -0.0000,  1.3478, -0.0000,  0.0000,  0.7792,\n",
       "          1.2965,  0.4906,  0.0000, -0.0000,  2.0095,  0.3751]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = selfembdrop(z)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs, conts.shape[1], 1, [300,200], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(31, 16)\n",
       "    (1): Embedding(7, 4)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(2, 1)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4)\n",
       "  (bn_cont): BatchNorm1d(621, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=643, out_features=300, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4)\n",
       "    (4): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4)\n",
       "    (8): Linear(in_features=200, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # we'll convert this to RMSE later\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "test_size = int(batch_size * .2)\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 1805.07336426\n",
      "epoch:   6  loss: 1805.07019043\n",
      "epoch:  11  loss: 1804.99182129\n",
      "epoch:  16  loss: 1804.98168945\n",
      "epoch:  21  loss: 1804.90478516\n",
      "epoch:  26  loss: 1804.88854980\n",
      "epoch:  31  loss: 1804.77673340\n",
      "epoch:  36  loss: 1804.73852539\n",
      "epoch:  41  loss: 1804.58605957\n",
      "epoch:  46  loss: 1804.54699707\n",
      "epoch:  51  loss: 1804.41662598\n",
      "epoch:  56  loss: 1804.24902344\n",
      "epoch:  61  loss: 1804.15405273\n",
      "epoch:  66  loss: 1803.87255859\n",
      "epoch:  71  loss: 1803.79333496\n",
      "epoch:  76  loss: 1803.54455566\n",
      "epoch:  81  loss: 1803.37402344\n",
      "epoch:  86  loss: 1803.01538086\n",
      "epoch:  91  loss: 1802.79443359\n",
      "epoch:  96  loss: 1802.43457031\n",
      "epoch: 101  loss: 1802.03747559\n",
      "epoch: 106  loss: 1801.72900391\n",
      "epoch: 111  loss: 1801.09643555\n",
      "epoch: 116  loss: 1800.86169434\n",
      "epoch: 121  loss: 1800.32849121\n",
      "epoch: 126  loss: 1799.86389160\n",
      "epoch: 131  loss: 1799.32775879\n",
      "epoch: 136  loss: 1799.05969238\n",
      "epoch: 141  loss: 1798.40344238\n",
      "epoch: 146  loss: 1797.72192383\n",
      "epoch: 151  loss: 1796.93530273\n",
      "epoch: 156  loss: 1796.46997070\n",
      "epoch: 161  loss: 1795.75317383\n",
      "epoch: 166  loss: 1794.92895508\n",
      "epoch: 171  loss: 1794.39562988\n",
      "epoch: 176  loss: 1793.48876953\n",
      "epoch: 181  loss: 1792.97387695\n",
      "epoch: 186  loss: 1791.81921387\n",
      "epoch: 191  loss: 1790.98852539\n",
      "epoch: 196  loss: 1790.20617676\n",
      "epoch: 201  loss: 1789.19482422\n",
      "epoch: 206  loss: 1788.01367188\n",
      "epoch: 211  loss: 1787.19799805\n",
      "epoch: 216  loss: 1785.98217773\n",
      "epoch: 221  loss: 1785.09069824\n",
      "epoch: 226  loss: 1784.39770508\n",
      "epoch: 231  loss: 1783.17614746\n",
      "epoch: 236  loss: 1781.81665039\n",
      "epoch: 241  loss: 1780.75622559\n",
      "epoch: 246  loss: 1779.77185059\n",
      "epoch: 251  loss: 1778.98510742\n",
      "epoch: 256  loss: 1777.25000000\n",
      "epoch: 261  loss: 1775.28796387\n",
      "epoch: 266  loss: 1773.94677734\n",
      "epoch: 271  loss: 1773.50915527\n",
      "epoch: 276  loss: 1771.50183105\n",
      "epoch: 281  loss: 1770.62695312\n",
      "epoch: 286  loss: 1768.95629883\n",
      "epoch: 291  loss: 1767.69848633\n",
      "epoch: 296  loss: 1765.96777344\n",
      "epoch: 301  loss: 1765.02697754\n",
      "epoch: 306  loss: 1762.99255371\n",
      "epoch: 311  loss: 1761.96386719\n",
      "epoch: 316  loss: 1760.19885254\n",
      "epoch: 321  loss: 1758.27624512\n",
      "epoch: 326  loss: 1756.98327637\n",
      "epoch: 331  loss: 1754.09765625\n",
      "epoch: 336  loss: 1753.62377930\n",
      "epoch: 341  loss: 1751.50036621\n",
      "epoch: 346  loss: 1750.62097168\n",
      "epoch: 351  loss: 1748.02575684\n",
      "epoch: 356  loss: 1746.60119629\n",
      "epoch: 361  loss: 1745.15075684\n",
      "epoch: 366  loss: 1742.49133301\n",
      "epoch: 371  loss: 1742.20288086\n",
      "epoch: 376  loss: 1738.10314941\n",
      "epoch: 381  loss: 1737.64794922\n",
      "epoch: 386  loss: 1735.42126465\n",
      "epoch: 391  loss: 1732.92785645\n",
      "epoch: 396  loss: 1732.38684082\n",
      "epoch: 401  loss: 1729.73254395\n",
      "epoch: 406  loss: 1726.71423340\n",
      "epoch: 411  loss: 1726.40161133\n",
      "epoch: 416  loss: 1722.55432129\n",
      "epoch: 421  loss: 1721.76623535\n",
      "epoch: 426  loss: 1719.50292969\n",
      "epoch: 431  loss: 1715.87219238\n",
      "epoch: 436  loss: 1714.96374512\n",
      "epoch: 441  loss: 1713.39538574\n",
      "epoch: 446  loss: 1709.06347656\n",
      "epoch: 451  loss: 1707.06591797\n",
      "epoch: 456  loss: 1706.81652832\n",
      "epoch: 461  loss: 1701.64379883\n",
      "epoch: 466  loss: 1701.38049316\n",
      "epoch: 471  loss: 1698.33361816\n",
      "epoch: 476  loss: 1696.83630371\n",
      "epoch: 481  loss: 1694.08032227\n",
      "epoch: 486  loss: 1690.41027832\n",
      "epoch: 491  loss: 1688.42175293\n",
      "epoch: 496  loss: 1684.62573242\n",
      "epoch: 501  loss: 1684.33483887\n",
      "epoch: 506  loss: 1682.83813477\n",
      "epoch: 511  loss: 1678.16906738\n",
      "epoch: 516  loss: 1676.45349121\n",
      "epoch: 521  loss: 1673.32958984\n",
      "epoch: 526  loss: 1671.12719727\n",
      "epoch: 531  loss: 1666.32458496\n",
      "epoch: 536  loss: 1665.41552734\n",
      "epoch: 541  loss: 1662.76416016\n",
      "epoch: 546  loss: 1660.83776855\n",
      "epoch: 551  loss: 1656.22497559\n",
      "epoch: 556  loss: 1654.16857910\n",
      "epoch: 561  loss: 1653.35034180\n",
      "epoch: 566  loss: 1648.74377441\n",
      "epoch: 571  loss: 1646.02441406\n",
      "epoch: 576  loss: 1642.89074707\n",
      "epoch: 581  loss: 1641.65270996\n",
      "epoch: 586  loss: 1637.43615723\n",
      "epoch: 591  loss: 1634.20043945\n",
      "epoch: 596  loss: 1629.38513184\n",
      "epoch: 601  loss: 1626.21301270\n",
      "epoch: 606  loss: 1624.15612793\n",
      "epoch: 611  loss: 1622.64428711\n",
      "epoch: 616  loss: 1617.85815430\n",
      "epoch: 621  loss: 1616.00769043\n",
      "epoch: 626  loss: 1614.05310059\n",
      "epoch: 631  loss: 1608.19165039\n",
      "epoch: 636  loss: 1607.41564941\n",
      "epoch: 641  loss: 1602.88378906\n",
      "epoch: 646  loss: 1599.47448730\n",
      "epoch: 651  loss: 1595.18786621\n",
      "epoch: 656  loss: 1593.06469727\n",
      "epoch: 661  loss: 1590.20849609\n",
      "epoch: 666  loss: 1587.80041504\n",
      "epoch: 671  loss: 1586.03234863\n",
      "epoch: 676  loss: 1579.94482422\n",
      "epoch: 681  loss: 1576.44616699\n",
      "epoch: 686  loss: 1572.67468262\n",
      "epoch: 691  loss: 1569.47961426\n",
      "epoch: 696  loss: 1567.51049805\n",
      "epoch: 701  loss: 1563.69726562\n",
      "epoch: 706  loss: 1564.66101074\n",
      "epoch: 711  loss: 1555.99682617\n",
      "epoch: 716  loss: 1553.81701660\n",
      "epoch: 721  loss: 1548.43554688\n",
      "epoch: 726  loss: 1544.17919922\n",
      "epoch: 731  loss: 1542.07849121\n",
      "epoch: 736  loss: 1537.31457520\n",
      "epoch: 741  loss: 1534.71020508\n",
      "epoch: 746  loss: 1532.35754395\n",
      "epoch: 751  loss: 1528.44982910\n",
      "epoch: 756  loss: 1522.12683105\n",
      "epoch: 761  loss: 1521.01379395\n",
      "epoch: 766  loss: 1515.33471680\n",
      "epoch: 771  loss: 1512.30212402\n",
      "epoch: 776  loss: 1509.63098145\n",
      "epoch: 781  loss: 1504.46948242\n",
      "epoch: 786  loss: 1504.22949219\n",
      "epoch: 791  loss: 1495.75073242\n",
      "epoch: 796  loss: 1497.89819336\n",
      "epoch: 801  loss: 1491.61193848\n",
      "epoch: 806  loss: 1480.46923828\n",
      "epoch: 811  loss: 1481.53320312\n",
      "epoch: 816  loss: 1475.09497070\n",
      "epoch: 821  loss: 1473.46301270\n",
      "epoch: 826  loss: 1469.95825195\n",
      "epoch: 831  loss: 1468.32763672\n",
      "epoch: 836  loss: 1462.88208008\n",
      "epoch: 841  loss: 1459.07751465\n",
      "epoch: 846  loss: 1455.53955078\n",
      "epoch: 851  loss: 1448.30578613\n",
      "epoch: 856  loss: 1445.73986816\n",
      "epoch: 861  loss: 1439.69824219\n",
      "epoch: 866  loss: 1437.49255371\n",
      "epoch: 871  loss: 1435.12207031\n",
      "epoch: 876  loss: 1423.27709961\n",
      "epoch: 881  loss: 1421.48242188\n",
      "epoch: 886  loss: 1419.73876953\n",
      "epoch: 891  loss: 1413.12829590\n",
      "epoch: 896  loss: 1409.40612793\n",
      "epoch: 901  loss: 1404.42883301\n",
      "epoch: 906  loss: 1400.41308594\n",
      "epoch: 911  loss: 1401.73095703\n",
      "epoch: 916  loss: 1394.23266602\n",
      "epoch: 921  loss: 1387.65039062\n",
      "epoch: 926  loss: 1382.07141113\n",
      "epoch: 931  loss: 1378.65710449\n",
      "epoch: 936  loss: 1376.55615234\n",
      "epoch: 941  loss: 1369.98156738\n",
      "epoch: 946  loss: 1366.75854492\n",
      "epoch: 951  loss: 1362.75170898\n",
      "epoch: 956  loss: 1357.90917969\n",
      "epoch: 961  loss: 1345.13769531\n",
      "epoch: 966  loss: 1346.97619629\n",
      "epoch: 971  loss: 1343.05566406\n",
      "epoch: 976  loss: 1338.11315918\n",
      "epoch: 981  loss: 1331.82495117\n",
      "epoch: 986  loss: 1329.13659668\n",
      "epoch: 991  loss: 1320.23071289\n",
      "epoch: 996  loss: 1323.87207031\n",
      "epoch: 1001  loss: 1316.57800293\n",
      "epoch: 1006  loss: 1305.42431641\n",
      "epoch: 1011  loss: 1306.92712402\n",
      "epoch: 1016  loss: 1304.55371094\n",
      "epoch: 1021  loss: 1297.87243652\n",
      "epoch: 1026  loss: 1293.03991699\n",
      "epoch: 1031  loss: 1286.29321289\n",
      "epoch: 1036  loss: 1280.68029785\n",
      "epoch: 1041  loss: 1283.79724121\n",
      "epoch: 1046  loss: 1275.21154785\n",
      "epoch: 1051  loss: 1265.37512207\n",
      "epoch: 1056  loss: 1263.46398926\n",
      "epoch: 1061  loss: 1259.20922852\n",
      "epoch: 1066  loss: 1247.78955078\n",
      "epoch: 1071  loss: 1255.31494141\n",
      "epoch: 1076  loss: 1236.04406738\n",
      "epoch: 1081  loss: 1237.54650879\n",
      "epoch: 1086  loss: 1230.67150879\n",
      "epoch: 1091  loss: 1235.70788574\n",
      "epoch: 1096  loss: 1219.13110352\n",
      "epoch: 1101  loss: 1212.95800781\n",
      "epoch: 1106  loss: 1214.54724121\n",
      "epoch: 1111  loss: 1205.99389648\n",
      "epoch: 1116  loss: 1205.20312500\n",
      "epoch: 1121  loss: 1193.97753906\n",
      "epoch: 1126  loss: 1191.33654785\n",
      "epoch: 1131  loss: 1193.69494629\n",
      "epoch: 1136  loss: 1184.50256348\n",
      "epoch: 1141  loss: 1167.67163086\n",
      "epoch: 1146  loss: 1172.28686523\n",
      "epoch: 1151  loss: 1156.02124023\n",
      "epoch: 1156  loss: 1158.17468262\n",
      "epoch: 1161  loss: 1152.54687500\n",
      "epoch: 1166  loss: 1153.46643066\n",
      "epoch: 1171  loss: 1149.00195312\n",
      "epoch: 1176  loss: 1141.07104492\n",
      "epoch: 1181  loss: 1129.59301758\n",
      "epoch: 1186  loss: 1127.61474609\n",
      "epoch: 1191  loss: 1120.95532227\n",
      "epoch: 1196  loss: 1108.95422363\n",
      "epoch: 1201  loss: 1113.41564941\n",
      "epoch: 1206  loss: 1103.71032715\n",
      "epoch: 1211  loss: 1095.55175781\n",
      "epoch: 1216  loss: 1097.61096191\n",
      "epoch: 1221  loss: 1083.23254395\n",
      "epoch: 1226  loss: 1072.43615723\n",
      "epoch: 1231  loss: 1079.75195312\n",
      "epoch: 1236  loss: 1057.20959473\n",
      "epoch: 1241  loss: 1067.36718750\n",
      "epoch: 1246  loss: 1053.42028809\n",
      "epoch: 1251  loss: 1052.55273438\n",
      "epoch: 1256  loss: 1048.28735352\n",
      "epoch: 1261  loss: 1036.33300781\n",
      "epoch: 1266  loss: 1031.03381348\n",
      "epoch: 1271  loss: 1040.18310547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1276  loss: 1020.70794678\n",
      "epoch: 1281  loss: 1022.41998291\n",
      "epoch: 1286  loss: 1007.60980225\n",
      "epoch: 1291  loss: 998.63140869\n",
      "epoch: 1296  loss: 1004.06713867\n",
      "epoch: 1301  loss: 981.05682373\n",
      "epoch: 1306  loss: 987.57873535\n",
      "epoch: 1311  loss: 982.59368896\n",
      "epoch: 1316  loss: 982.01800537\n",
      "epoch: 1321  loss: 967.41699219\n",
      "epoch: 1326  loss: 970.57299805\n",
      "epoch: 1331  loss: 955.44506836\n",
      "epoch: 1336  loss: 944.76074219\n",
      "epoch: 1341  loss: 951.91412354\n",
      "epoch: 1346  loss: 938.89410400\n",
      "epoch: 1351  loss: 929.28570557\n",
      "epoch: 1356  loss: 926.22308350\n",
      "epoch: 1361  loss: 928.95812988\n",
      "epoch: 1366  loss: 923.96325684\n",
      "epoch: 1371  loss: 902.97796631\n",
      "epoch: 1376  loss: 901.41229248\n",
      "epoch: 1381  loss: 900.42523193\n",
      "epoch: 1386  loss: 892.54302979\n",
      "epoch: 1391  loss: 886.33581543\n",
      "epoch: 1396  loss: 887.13928223\n",
      "epoch: 1401  loss: 881.47308350\n",
      "epoch: 1406  loss: 871.69244385\n",
      "epoch: 1411  loss: 860.36535645\n",
      "epoch: 1416  loss: 844.85888672\n",
      "epoch: 1421  loss: 840.68829346\n",
      "epoch: 1426  loss: 845.81219482\n",
      "epoch: 1431  loss: 836.03222656\n",
      "epoch: 1436  loss: 825.07678223\n",
      "epoch: 1441  loss: 826.28161621\n",
      "epoch: 1446  loss: 815.64727783\n",
      "epoch: 1451  loss: 810.86779785\n",
      "epoch: 1456  loss: 808.03320312\n",
      "epoch: 1461  loss: 803.61883545\n",
      "epoch: 1466  loss: 779.80151367\n",
      "epoch: 1471  loss: 783.45147705\n",
      "epoch: 1476  loss: 783.10223389\n",
      "epoch: 1481  loss: 772.40924072\n",
      "epoch: 1486  loss: 760.68328857\n",
      "epoch: 1491  loss: 756.09692383\n",
      "epoch: 1496  loss: 754.71466064\n",
      "epoch: 1501  loss: 746.63513184\n",
      "epoch: 1506  loss: 737.68194580\n",
      "epoch: 1511  loss: 730.50091553\n",
      "epoch: 1516  loss: 730.18432617\n",
      "epoch: 1521  loss: 735.55908203\n",
      "epoch: 1526  loss: 703.95239258\n",
      "epoch: 1531  loss: 706.34271240\n",
      "epoch: 1536  loss: 696.63342285\n",
      "epoch: 1541  loss: 690.43133545\n",
      "epoch: 1546  loss: 688.38848877\n",
      "epoch: 1551  loss: 670.93243408\n",
      "epoch: 1556  loss: 679.98669434\n",
      "epoch: 1561  loss: 667.30059814\n",
      "epoch: 1566  loss: 661.14062500\n",
      "epoch: 1571  loss: 644.79504395\n",
      "epoch: 1576  loss: 659.82342529\n",
      "epoch: 1581  loss: 650.98638916\n",
      "epoch: 1586  loss: 631.76275635\n",
      "epoch: 1591  loss: 606.68255615\n",
      "epoch: 1596  loss: 613.94055176\n",
      "epoch: 1601  loss: 613.19793701\n",
      "epoch: 1606  loss: 599.42877197\n",
      "epoch: 1611  loss: 601.37591553\n",
      "epoch: 1616  loss: 590.34118652\n",
      "epoch: 1621  loss: 591.64147949\n",
      "epoch: 1626  loss: 572.56152344\n",
      "epoch: 1631  loss: 568.69207764\n",
      "epoch: 1636  loss: 560.34783936\n",
      "epoch: 1641  loss: 563.07934570\n",
      "epoch: 1646  loss: 528.35321045\n",
      "epoch: 1651  loss: 550.98394775\n",
      "epoch: 1656  loss: 533.92077637\n",
      "epoch: 1661  loss: 538.23779297\n",
      "epoch: 1666  loss: 509.12164307\n",
      "epoch: 1671  loss: 501.62600708\n",
      "epoch: 1676  loss: 502.68789673\n",
      "epoch: 1681  loss: 507.14422607\n",
      "epoch: 1686  loss: 498.12634277\n",
      "epoch: 1691  loss: 484.60427856\n",
      "epoch: 1696  loss: 475.16690063\n",
      "epoch: 1701  loss: 473.83911133\n",
      "epoch: 1706  loss: 465.86428833\n",
      "epoch: 1711  loss: 447.43725586\n",
      "epoch: 1716  loss: 462.11367798\n",
      "epoch: 1721  loss: 453.95581055\n",
      "epoch: 1726  loss: 428.92565918\n",
      "epoch: 1731  loss: 414.61999512\n",
      "epoch: 1736  loss: 419.90942383\n",
      "epoch: 1741  loss: 411.42486572\n",
      "epoch: 1746  loss: 413.10647583\n",
      "epoch: 1751  loss: 403.04061890\n",
      "epoch: 1756  loss: 403.21746826\n",
      "epoch: 1761  loss: 395.32565308\n",
      "epoch: 1766  loss: 389.31045532\n",
      "epoch: 1771  loss: 379.72402954\n",
      "epoch: 1776  loss: 372.51333618\n",
      "epoch: 1781  loss: 361.13357544\n",
      "epoch: 1786  loss: 365.10943604\n",
      "epoch: 1791  loss: 352.55715942\n",
      "epoch: 1796  loss: 309.54611206\n",
      "epoch: 1801  loss: 326.15689087\n",
      "epoch: 1806  loss: 321.73345947\n",
      "epoch: 1811  loss: 311.05816650\n",
      "epoch: 1816  loss: 309.57098389\n",
      "epoch: 1821  loss: 319.92160034\n",
      "epoch: 1826  loss: 292.92507935\n",
      "epoch: 1831  loss: 271.08233643\n",
      "epoch: 1836  loss: 281.14694214\n",
      "epoch: 1841  loss: 276.22738647\n",
      "epoch: 1846  loss: 275.24548340\n",
      "epoch: 1851  loss: 274.18038940\n",
      "epoch: 1856  loss: 252.91490173\n",
      "epoch: 1861  loss: 225.99784851\n",
      "epoch: 1866  loss: 247.35359192\n",
      "epoch: 1871  loss: 221.21929932\n",
      "epoch: 1876  loss: 233.24801636\n",
      "epoch: 1881  loss: 223.95085144\n",
      "epoch: 1886  loss: 221.53779602\n",
      "epoch: 1891  loss: 204.77291870\n",
      "epoch: 1896  loss: 197.37977600\n",
      "epoch: 1901  loss: 193.68339539\n",
      "epoch: 1906  loss: 188.41883850\n",
      "epoch: 1911  loss: 180.47129822\n",
      "epoch: 1916  loss: 184.57743835\n",
      "epoch: 1921  loss: 173.09086609\n",
      "epoch: 1926  loss: 169.94458008\n",
      "epoch: 1931  loss: 170.12933350\n",
      "epoch: 1936  loss: 159.16194153\n",
      "epoch: 1941  loss: 164.31680298\n",
      "epoch: 1946  loss: 146.37005615\n",
      "epoch: 1951  loss: 150.47706604\n",
      "epoch: 1956  loss: 138.17312622\n",
      "epoch: 1961  loss: 150.02224731\n",
      "epoch: 1966  loss: 136.80178833\n",
      "epoch: 1971  loss: 122.81152344\n",
      "epoch: 1976  loss: 116.37326813\n",
      "epoch: 1981  loss: 128.65362549\n",
      "epoch: 1986  loss: 116.36025238\n",
      "epoch: 1991  loss: 115.57466125\n",
      "epoch: 1996  loss: 111.24714661\n",
      "epoch: 2001  loss: 115.79945374\n",
      "epoch: 2006  loss: 123.96028900\n",
      "epoch: 2011  loss: 109.52875519\n",
      "epoch: 2016  loss: 112.37376404\n",
      "epoch: 2021  loss: 114.21871948\n",
      "epoch: 2026  loss: 111.87828827\n",
      "epoch: 2031  loss: 119.91938782\n",
      "epoch: 2036  loss: 124.50354004\n",
      "epoch: 2041  loss: 111.49349976\n",
      "epoch: 2046  loss: 121.27209473\n",
      "epoch: 2051  loss: 86.74222565\n",
      "epoch: 2056  loss: 106.64002991\n",
      "epoch: 2061  loss: 119.08245087\n",
      "epoch: 2066  loss: 113.85070801\n",
      "epoch: 2071  loss: 108.23538971\n",
      "epoch: 2076  loss: 102.89192200\n",
      "epoch: 2081  loss: 100.74523926\n",
      "epoch: 2086  loss: 103.02906799\n",
      "epoch: 2091  loss: 112.58821106\n",
      "epoch: 2096  loss: 108.72967529\n",
      "epoch: 2101  loss: 103.02068329\n",
      "epoch: 2106  loss: 104.10412598\n",
      "epoch: 2111  loss: 108.50885010\n",
      "epoch: 2116  loss: 121.75506592\n",
      "epoch: 2121  loss: 95.38442993\n",
      "epoch: 2126  loss: 100.37116241\n",
      "epoch: 2131  loss: 121.50635529\n",
      "epoch: 2136  loss: 94.28032684\n",
      "epoch: 2141  loss: 119.74602509\n",
      "epoch: 2146  loss: 101.89596558\n",
      "epoch: 2151  loss: 100.25782013\n",
      "epoch: 2156  loss: 108.27519989\n",
      "epoch: 2161  loss: 105.74853516\n",
      "epoch: 2166  loss: 119.46273804\n",
      "epoch: 2171  loss: 92.04589081\n",
      "epoch: 2176  loss: 107.66530609\n",
      "epoch: 2181  loss: 119.47547150\n",
      "epoch: 2186  loss: 103.48995972\n",
      "epoch: 2191  loss: 107.21063232\n",
      "epoch: 2196  loss: 103.19549561\n",
      "epoch: 2201  loss: 105.17470551\n",
      "epoch: 2206  loss: 88.14836121\n",
      "epoch: 2211  loss: 96.99142456\n",
      "epoch: 2216  loss: 98.95774078\n",
      "epoch: 2221  loss: 106.73110962\n",
      "epoch: 2226  loss: 119.52426147\n",
      "epoch: 2231  loss: 100.57356262\n",
      "epoch: 2236  loss: 95.34844971\n",
      "epoch: 2241  loss: 104.59747314\n",
      "epoch: 2246  loss: 112.45313263\n",
      "epoch: 2251  loss: 115.32010651\n",
      "epoch: 2256  loss: 110.44682312\n",
      "epoch: 2261  loss: 103.81941986\n",
      "epoch: 2266  loss: 111.48194122\n",
      "epoch: 2271  loss: 111.35074615\n",
      "epoch: 2276  loss: 104.54645538\n",
      "epoch: 2281  loss: 118.88938904\n",
      "epoch: 2286  loss: 102.32681274\n",
      "epoch: 2291  loss: 101.07997131\n",
      "epoch: 2296  loss: 100.55914307\n",
      "epoch: 2301  loss: 111.41706085\n",
      "epoch: 2306  loss: 102.52892303\n",
      "epoch: 2311  loss: 109.00756836\n",
      "epoch: 2316  loss: 106.52715302\n",
      "epoch: 2321  loss: 106.01685333\n",
      "epoch: 2326  loss: 99.92045593\n",
      "epoch: 2331  loss: 106.01026917\n",
      "epoch: 2336  loss: 112.67575073\n",
      "epoch: 2341  loss: 114.25503540\n",
      "epoch: 2346  loss: 105.77549744\n",
      "epoch: 2351  loss: 91.66999817\n",
      "epoch: 2356  loss: 101.02606201\n",
      "epoch: 2361  loss: 99.04376984\n",
      "epoch: 2366  loss: 102.80413818\n",
      "epoch: 2371  loss: 107.20771027\n",
      "epoch: 2376  loss: 99.10215759\n",
      "epoch: 2381  loss: 80.65557861\n",
      "epoch: 2386  loss: 114.83648682\n",
      "epoch: 2391  loss: 103.72470093\n",
      "epoch: 2396  loss: 105.39942932\n",
      "epoch: 2401  loss: 99.23038483\n",
      "epoch: 2406  loss: 123.74761200\n",
      "epoch: 2411  loss: 112.76584625\n",
      "epoch: 2416  loss: 97.50234222\n",
      "epoch: 2421  loss: 103.76267242\n",
      "epoch: 2426  loss: 111.00880432\n",
      "epoch: 2431  loss: 103.83989716\n",
      "epoch: 2436  loss: 90.95985413\n",
      "epoch: 2441  loss: 107.07610321\n",
      "epoch: 2446  loss: 102.29413605\n",
      "epoch: 2451  loss: 100.88997650\n",
      "epoch: 2456  loss: 107.25444794\n",
      "epoch: 2461  loss: 106.94685364\n",
      "epoch: 2466  loss: 100.26460266\n",
      "epoch: 2471  loss: 115.72061157\n",
      "epoch: 2476  loss: 110.41355896\n",
      "epoch: 2481  loss: 98.32181549\n",
      "epoch: 2486  loss: 102.12451935\n",
      "epoch: 2491  loss: 100.94312286\n",
      "epoch: 2496  loss: 106.68195343\n",
      "epoch: 2501  loss: 95.70097351\n",
      "epoch: 2506  loss: 96.69124603\n",
      "epoch: 2511  loss: 111.17659760\n",
      "epoch: 2516  loss: 115.90607452\n",
      "epoch: 2521  loss: 100.56505585\n",
      "epoch: 2526  loss: 107.50315094\n",
      "epoch: 2531  loss: 100.76839447\n",
      "epoch: 2536  loss: 113.40695953\n",
      "epoch: 2541  loss: 123.76725006\n",
      "epoch: 2546  loss: 98.37776184\n",
      "epoch: 2551  loss: 97.33202362\n",
      "epoch: 2556  loss: 96.12663269\n",
      "epoch: 2561  loss: 98.11190796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2566  loss: 118.47858429\n",
      "epoch: 2571  loss: 106.05198669\n",
      "epoch: 2576  loss: 101.28065491\n",
      "epoch: 2581  loss: 115.60653687\n",
      "epoch: 2586  loss: 85.63512421\n",
      "epoch: 2591  loss: 98.98529053\n",
      "epoch: 2596  loss: 103.98904419\n",
      "epoch: 2601  loss: 117.14859772\n",
      "epoch: 2606  loss: 108.83284760\n",
      "epoch: 2611  loss: 94.16059875\n",
      "epoch: 2616  loss: 103.20400238\n",
      "epoch: 2621  loss: 99.68976593\n",
      "epoch: 2626  loss: 119.56712341\n",
      "epoch: 2631  loss: 113.88819122\n",
      "epoch: 2636  loss: 95.54782104\n",
      "epoch: 2641  loss: 122.82216644\n",
      "epoch: 2646  loss: 116.85504150\n",
      "epoch: 2651  loss: 101.98213959\n",
      "epoch: 2656  loss: 115.75311279\n",
      "epoch: 2661  loss: 98.70677185\n",
      "epoch: 2666  loss: 118.72725677\n",
      "epoch: 2671  loss: 95.64060974\n",
      "epoch: 2676  loss: 100.29425049\n",
      "epoch: 2681  loss: 107.53242493\n",
      "epoch: 2686  loss: 123.69490051\n",
      "epoch: 2691  loss: 97.82137299\n",
      "epoch: 2696  loss: 110.21655273\n",
      "epoch: 2701  loss: 100.42783356\n",
      "epoch: 2706  loss: 114.52444458\n",
      "epoch: 2711  loss: 107.58152008\n",
      "epoch: 2716  loss: 104.40861511\n",
      "epoch: 2721  loss: 104.00120544\n",
      "epoch: 2726  loss: 99.46723175\n",
      "epoch: 2731  loss: 108.60430145\n",
      "epoch: 2736  loss: 105.02955627\n",
      "epoch: 2741  loss: 112.91309357\n",
      "epoch: 2746  loss: 113.00688934\n",
      "epoch: 2751  loss: 110.10570526\n",
      "epoch: 2756  loss: 98.83724213\n",
      "epoch: 2761  loss: 103.92369080\n",
      "epoch: 2766  loss: 112.72739410\n",
      "epoch: 2771  loss: 113.76795959\n",
      "epoch: 2776  loss: 118.61858368\n",
      "epoch: 2781  loss: 98.94098663\n",
      "epoch: 2786  loss: 106.76745605\n",
      "epoch: 2791  loss: 116.30876160\n",
      "epoch: 2796  loss: 106.45875549\n",
      "epoch: 2801  loss: 96.48772430\n",
      "epoch: 2806  loss: 99.72016144\n",
      "epoch: 2811  loss: 89.87991333\n",
      "epoch: 2816  loss: 110.56007385\n",
      "epoch: 2821  loss: 110.31745911\n",
      "epoch: 2826  loss: 88.09229279\n",
      "epoch: 2831  loss: 121.59344482\n",
      "epoch: 2836  loss: 98.48618317\n",
      "epoch: 2841  loss: 111.14284515\n",
      "epoch: 2846  loss: 96.46463776\n",
      "epoch: 2851  loss: 90.67721558\n",
      "epoch: 2856  loss: 99.04314423\n",
      "epoch: 2861  loss: 95.07118225\n",
      "epoch: 2866  loss: 96.03234100\n",
      "epoch: 2871  loss: 102.89063263\n",
      "epoch: 2876  loss: 91.12476349\n",
      "epoch: 2881  loss: 107.72880554\n",
      "epoch: 2886  loss: 121.02685547\n",
      "epoch: 2891  loss: 116.38185883\n",
      "epoch: 2896  loss: 104.87260437\n",
      "epoch: 2901  loss: 107.24188995\n",
      "epoch: 2906  loss: 108.37581635\n",
      "epoch: 2911  loss: 103.77790833\n",
      "epoch: 2916  loss: 115.14410400\n",
      "epoch: 2921  loss: 101.95414734\n",
      "epoch: 2926  loss: 109.06498718\n",
      "epoch: 2931  loss: 112.11625671\n",
      "epoch: 2936  loss: 113.25535583\n",
      "epoch: 2941  loss: 121.22054291\n",
      "epoch: 2946  loss: 92.74176025\n",
      "epoch: 2951  loss: 103.99061584\n",
      "epoch: 2956  loss: 108.05700684\n",
      "epoch: 2961  loss: 103.91931152\n",
      "epoch: 2966  loss: 112.64714050\n",
      "epoch: 2971  loss: 109.04251862\n",
      "epoch: 2976  loss: 105.29856873\n",
      "epoch: 2981  loss: 89.93241119\n",
      "epoch: 2986  loss: 104.99320221\n",
      "epoch: 2991  loss: 95.37685394\n",
      "epoch: 2996  loss: 111.73046112\n",
      "epoch: 3000  loss: 122.53931427\n",
      "\n",
      "Duration: 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 3000\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%5 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 125.66398621\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = torch.sqrt(criterion(y_val, y_test))\n",
    "print(f'RMSE: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PREDICTED   ACTUAL     DIFF\n",
      " 1. 1816.7661 1724.3000  92.4661\n",
      " 2. 1797.4097 1727.2000  70.2097\n",
      " 3. 1759.0933 1726.5000  32.5933\n",
      " 4. 1692.4919 1721.9000  29.4081\n",
      " 5. 1894.3032 1682.9000 211.4032\n",
      " 6. 1926.0127 1703.8000 222.2126\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "for i in range(6):\n",
    "    diff = np.abs(y_val[i].item()-y_test[i].item())\n",
    "    print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
